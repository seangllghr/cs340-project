% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
11pt,
titlepage,
]{article}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
\usepackage{unicode-math}
\defaultfontfeatures{Scale=MatchLowercase}
\defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Securities Tracking, Observation, and Computational Knowledge System:},
  pdfauthor={Sean Gallagher},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[hmargin=1in,vmargin=0.9in]{geometry}
\usepackage{etoolbox}
\usepackage{listings}
\newcommand{\passthrough}[1]{#1}
\lstset{defaultdialect=[5.3]Lua}
\lstset{defaultdialect=[x86masm]Assembler}
% Requires package: color.
\definecolor{mediumblue}{rgb}{0.0, 0.0, 0.8}
\definecolor{forestgreen}{rgb}{0.13, 0.55, 0.13}
\definecolor{darkviolet}{rgb}{0.58, 0.0, 0.83}
\definecolor{royalblue}{rgb}{0.25, 0.41, 0.88}
\definecolor{crimson}{rgb}{0.86, 0.8, 0.24}
\definecolor{lightgray}{rgb}{0.9, 0.9, 0.9}
\definecolor{mediumgray}{rgb}{0.3, 0.4, 0.4}
\lstset{
  backgroundcolor=\color{lightgray},
  basicstyle=\linespread{1}\ttfamily,
  commentstyle=\color{mediumgray}\upshape,
  fillcolor=\color{mediumgray},
  frame=leftline,
  identifierstyle=\color{black},
  keywordstyle=\color{mediumblue},
  keywordstyle={[2]\color{darkviolet}},
  keywordstyle={[3]\color{royalblue}},
  numberstyle=\tiny\color{black},
  rulecolor=\color{black},
  showlines=true,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stringstyle=\color{forestgreen},
  upquote=true  % requires textcomp
}
% decrease spacing after figures
\AtEndEnvironment{figure}{\vskip -12pt}

\usepackage{graphicx}
\usepackage{enumitem}
\setlist[itemize]{topsep=0pt}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}\setstretch{1.25}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Securities Tracking, Observation, and Computational Knowledge System:}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Documentation and Development Report}
\author{Sean Gallagher}
\date{}

\usepackage[bottom]{footmisc}

\usepackage{tikz}
\usetikzlibrary{arrows,positioning}
\usepackage[font=small]{caption}
\usepackage{mathtools}

% Remove extra spacing under titles
\usepackage{titlesec}
\titlespacing*{\section}{0pt}{0pt}{0pt}
\titlespacing*{\subsection}{0pt}{0pt}{0pt}
\titlespacing*{\subsubsection}{0pt}{0pt}{0pt}

% afterpage lets us call commands at the end of the current page
\usepackage{afterpage}

\usepackage{titling}

\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.8}
\setcounter{topnumber}{1}
\setcounter{bottomnumber}{1}
\setcounter{totalnumber}{2}
\renewcommand{\textfraction}{0.07}
\renewcommand{\floatpagefraction}{0.7}

% Bully the widow and orphan settings
\clubpenalty=10000
\widowpenalty=10000

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOCUMENT STARTS HERE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

% ECMAScript 2015 (ES6) definition by Gary Hammock
\lstdefinelanguage[ECMAScript2015]{JavaScript}[]{JavaScript}{
  morekeywords=[1]{await, async, case, catch, class, const, default, do, enum,
    export, extends, finally, from, implements, import, instanceof, let, static,
    super, switch, throw, try}, morestring=[b]` % Interpolation strings.
}
% JavaScript version 1.1 by Gary Hammock
\lstdefinelanguage{JavaScript}{
  morekeywords=[1]{break, continue, delete, else, for, function, if, in, new,
    return, this, typeof, var, void, while, with},
  % Literals, primitive types, and reference types.
  morekeywords=[2]{false, null, true, boolean, number, undefined, Array,
    Boolean, Date, Math, Number, String, Object},
  % Built-ins.
  morekeywords=[3]{eval, parseInt, parseFloat, escape, unescape}, sensitive,
  morecomment=[s]{/*}{*/}, morecomment=[l]//,
  morecomment=[s]{/**}{*/}, % JavaDoc style comments
  morestring=[b]', morestring=[b]"
}[keywords, comments, strings]
\lstalias[]{ES6}[ECMAScript2015]{Javascript}
\lstdefinestyle{JSES6Base}{
  backgroundcolor=\color{lightgray},
  breakatwhitespace=false,
  breaklines=false,
  captionpos=b,
  columns=fullflexible,
  commentstyle=\color{mediumgray}\upshape,
  emph={},
  emphstyle=\color{crimson},
  extendedchars=true,  % requires inputenc
  fontadjust=true,
  frame=leftline,
  identifierstyle=\color{black},
  keepspaces=true,
  keywordstyle=\color{mediumblue},
  keywordstyle={[2]\color{darkviolet}},
  keywordstyle={[3]\color{royalblue}},
  numbers=left,
  numbersep=5pt,
  numberstyle=\tiny\color{black},
  rulecolor=\color{black},
  showlines=true,
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  stringstyle=\color{forestgreen},
  tabsize=2,
  upquote=true  % requires textcomp
}
\lstdefinestyle{JavaScript}{language=JavaScript, style=JSES6Base}
\lstdefinestyle{ES6}{language=ES6, style=JSES6Base}

\pretitle{\begin{center}\large}
  \posttitle{\end{center}}
\preauthor{\begin{center}\small}
  \postauthor{\\
  \noindent CS-340: Client-Server Development\\
  \noindent Southern New Hampshire University
  \end{center}
}
\maketitle

\setstretch{2}


Professionals in the Financial Services sector must track and account for a
milieu of statistics and data in the course of the daily conduct of business.
Fortunately, computer systems present an opportunity to facilitate the
acquisition and analysis of this knowledge in new and compelling ways. The
Securities Tracking, Observation, and Computational Knowledge
System\footnote{Yes, that's quite a mouthful. We know; we're working on it.} is
one such system---one which aims to revolutionize the financial services sector.
This report documents the system, its features and functions, and the interface
it exposes to enable those ends. The system is built on Node.js in a modern
Linux operating environment, familiar to both administrators and engineering
teams. This allows developers to more flexibly move from back end to front end
development and focus on creating powerful, responsive interfaces for their
users.

This documentation consists of two sections. The first covers administration of
the system back end through the life cycle of included data. Following a
discussion of database initialization and indexing, the report will cover the
basic command line tools included with the product and their applications in
manipulating and validating the data stored within the installed system. The
second section details the Web Service API. This API---which is intended to be
the primary interface for both daily use and administration of the
system---includes endpoints for basic database manipulation and the two
specified reporting interfaces. Each section includes detailed descriptions of
operations involved in system administration, as well as screenshots
illustrating operations and their results. Names of variables, options,
executable scripts or programs, and short commands meant to be entered at a
Linux or MongoDB shell prompt are set inline in
\texttt{monospace}\footnote{Note that this document assumes that the
\texttt{cs340-project/bin} directory is in the user's \texttt{\$PATH}, and omits
`\texttt{./}' from any such commands.}. Long
commands, especially those that extend across more than one line, will be set
according to the following convention:

\begin{lstlisting}
  > command [optional value] <mandatory value>
\end{lstlisting}

\section{Installing, Initializing, and Administering the System}

The Securities Tracking, Observation, and Computational Knowledge
System\footnote{We really need a new name for this\ldots{}} is built on MongoDB,
a document-oriented NoSQL database system, and Node.js, a server-side runtime
for modern JavaScript based on Google's V8 JavaScript engine. It is designed and
tested to run on modern Linux platforms---development and testing was done on
Ubuntu 20.04 LTS, though any recent Linux distribution should suffice. As a full
discussion of the pertinent concepts relating to each of these technologies
could fill several textbooks, this document assumes the prospective
administrator is familiar with installing and maintaining a Linux system;
installing, configuring, and securing a MongoDB server instance; and basic usage
of Node's \texttt{npm} package manager. Once these dependencies are met, issue
the following command to download the system files:

\begin{lstlisting}[language=bash]
  > git clone --depth 1 https://github.com/seangllghr/cs340-project
\end{lstlisting}

\noindent As with any \texttt{git\ clone} operation, you can specify a custom
installation directory at the end of the command. Once the files have been
downloaded, enter the installation directory and run \texttt{npm\ install} to
install the necessary Node dependencies

\subsection{System Initialization and Configuration}

Before the installed system can be used to generate insights into financial
securities markets, it must be configured and populated with data. This process
consists of three principal steps: (a) importing the data and configuring the
application to access the database, and (b) indexing the database for
performance. Each of these steps plays a vital role in ensuring that the
configured application suits the needs of the front-end development team and the
system's target users.

\subsubsection{Database creation and import}

\begin{figure}[htbp]
  \includegraphics[width=\textwidth]{build/img/import.png}
  \caption{Importing data from a JSON file into the database and verifying
    correct import from the MongoDB shell.}
  \label{fig:import}
\end{figure}

Once the application is operational, data will be managed and manipulated using
the Web Service API; however, the database should be populated during initial
configuration using data stored in JSON file. While the specifics of the
application will dictate the details of the schema, the included utilities and
API expect each stock record to have the following fields:

\begin{itemize}
    \tightlist
  \item \texttt{Ticker} (unique)
  \item \texttt{Sector}
  \item \texttt{Industry}
  \item \texttt{Volume}
  \item \texttt{50-Day\ Simple\ Moving\ Average}
  \item \texttt{Analyst\ Recom}
\end{itemize}

Figure \ref{fig:import} depicts the process of importing seed data into the database
instance using the \texttt{mongoimport} command. While the specific construction
of the command will depend on the environment and configuration of the MongoDB
server, the general form is:

\begin{lstlisting}[language=bash]
  mongoimport \
  [--host=<host>] [--port=<port>] \
  [authentication opts] \
  [--db=<db>] [--collection=<collection>] \
  <file>
\end{lstlisting}

\noindent Once the \texttt{mongoimport} tool has finished importing data from
the JSON file, log into the MongoDB shell and issue a simple \texttt{findOne()}
query to verify that the data has imported correctly, as illustrated in the
figure. After verifying that the database has imported correctly, set the
\texttt{dbName} and \texttt{colName} values in the the \texttt{config.json} file
in the application's root directory to enable the application back end to access
the database.

\subsubsection{Index Design and Implementation}

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/simple-index.png}
  \caption{Creation of a simple ascending index on the \texttt{ticker} field.}
  \label{fig:simple-index}
\end{figure}

Index design and implementation is, like the broader topic of general MongoDB
administration, too vast to cover in this report. While the development team
creating the specific queries requested for a given application will know best
what indices will offer the greatest performance benefit for their application,
some generalizations can be offered. As searching for a specific stock or
security will likely be a staple of most analysts' workflows, a simple index on
the \texttt{Ticker} field will benefit most applications. Creation of such an
index is straightforward: after logging into the MongoDB shell and selecting the
application database, issue the following command (illustrated in Figure
\ref{fig:simple-index}:

\begin{lstlisting}[style=ES6]
  db.<collection>.createIndex({"Ticker": 1})
\end{lstlisting}

\begin{figure}[tbp]
  \includegraphics[width=\textwidth]{build/img/compound-index.png}
  \caption{Creation of a compound index on the \texttt{Industry} and
    \texttt{Analyst Recom} fields will increase performance for the Industry
    Report query.}
  \label{fig:compound-index}
\end{figure}

In addition to simple indices, one or more compound indices may be necessary for
optimal performance of a given application. A variety of considerations
influence the order in which indexed fields appear in a compound index, and
these factors are highly dependent on the queries required to generate reports
used in a given implementation. To illustrate this, take the example Industry
Report provided with this software. While a full description will be included in
the API section of this document, the report, in brief, returns a list of the
top 5 stocks in a user-supplied industry. A compound index across the
\texttt{Industry} (ascending) and \texttt{Analyst Recom} (descending) fields
(shown in Figure \ref{fig:compound-index}) will improve the performance of this report
considerably.

\subsection{Command Line Tools and Library Functions}

The Securities Tracking, Obs---okay, you know what, just call it
STOCKS\footnote{I'll see myself out}---ships with several tools for manipulating
the database back end from the command line. These tools are not meant to be
exhaustive replacements for the MongoDB shell; rather they aim to facilitate
some common interactions and provide examples of how the utilities and scripts
can harness the internal application architecture to enhance and automate
aspects of the typical administrative workflow.

\subsubsection{Library Functions}

Two libraries of utility functions are provided with STOCKS. The first,
\texttt{jsonUtils}, provides functions for loading and JSON stock and security
data. While Node provides native functions for manipulating JSON data through
the \texttt{JSON} object, the \texttt{jsonUtils} library provides
abstractions for creating a string from a stream, parsing that stream into a
native JavaScript object, and scanning for and replacing query terms, such as
\texttt{\$oid} and \texttt{\$date} with their respective native JavaScript
objects.

The other library, \texttt{cli-utils}, provides two generalized prompt
functions. Because Node.js relies heavily on asynchronous programming
techniques, synchronous I/O akin to what is offered by other common server-side
languages is quite a bit more complex in Node. STOCKS relies on an outside
library to abstract away that complexity, and offers two straightforward prompt
functions---\texttt{promptForString()} and \texttt{promptForNumber()}---that
mimic traditional synchronous I/O for command line tools.

\subsubsection{Aside: \texttt{stock-client.sh}, a Rudimentary API Front End}

\begin{lstlisting}
  Usage: stock-client delete [ticker]
         stock-client industry-report [industry]
         stock-client insert <JSON/YAML stock document>
         stock-client read [ticker]
         stock-client stock-report <JSON/YAML ticker list>
         stock-client update <ticker> <JSON/YAML update document>
\end{lstlisting}

\begin{figure}[tbp]
  \includegraphics[width=\textwidth]{build/img/sc-r-mongoshell-comp.png}
  \caption{\texttt{stock-client read} offers a user-friendly, paged alternative
    to manually verifying the following command-line utilities from the MongoDB
    shell.}
  \label{fig:sc-r-mongoshell-comp}
\end{figure}

Take a look in the \texttt{bin} folder, and one file stands out as immediately
different than the rest: \texttt{stock-client.sh}. This script, written in Bash
and reliant on several Linux command line tools, started as a platform that the
STOCKS development team used to test the STOCKS Web Service API. Over the course
of this testing, \texttt{stock-client.sh} gradually expanded in scope, to the
point where it is effectively a full-featured command line client for the STOCKS
Web Service API. It provides this interface using an executable-command-operand
syntax that should be familiar to most Linux users, summarized above.

Aside from Bash, the client depends on a number of *nix command line tools to
process input and server responses. At the client's core, \texttt{curl} is used
to access the STOCKS Web Service API. The \texttt{read}, \texttt{delete}, and
\texttt{industry-report} commands take input as a simple string, but the
\texttt{insert}, \texttt{update}, and \texttt{stock-report} commands take input
in the form of a stock record document, update document\footnote{Technically,
\texttt{update} also takes a \texttt{Ticker} string, as well.}, and a list of
\texttt{Ticker} symbols. Using a tool called \texttt{yq}, a command line YAML
processor, the client is able to accept both JSON and YAML for these input
documents. The client also uses \texttt{yq} to pretty-print (as human-friendly
YAML) the output of commands that return JSON data. Additionally, the client
filters the stock and industry reports using another tool called \texttt{jq} to
present only the most relevant information to the user, and \texttt{less} is
used for paging. Assuming these dependencies can be satisfied, the client
\textit{should} run on any system with a Bash shell. The client has been tested
successfully on bare-metal Ubuntu 20.04 and Windows Subsystem for Linux 2 (also
running Ubuntu 20.04). The client is written to interface with a STOCKS server
running on \texttt{localhost} by default. There is currently no run-time option
or configuration file to specify a server; however, the single variable
\texttt{hostname} can be set within the script itself to allow
\texttt{stock-client} to access a remote STOCKS server.

The second section of this report goes into detail about the specific API
endpoints and operations supported by the client; additional discussion in this
section would be redundant. However, because the interface is straightforward,
the output concise, and the client offers paged output by default for
full-record read operations, the author recommends that administrators use
\texttt{stock-client read} to verify correct functioning of the command line
tools in this section. Figure \ref{fig:sc-r-mongoshell-comp} illustrates the
difference between a Mongo Shell \texttt{find} operation and the
\texttt{stock-client read} command---namely, that there is essentially no
difference, except for the significant keystroke savings and quality of life
improvements for users of the latter. Screenshots from \texttt{stock-client
read} are used to verify the command line tools and API calls throughout this
document, primarily for space-saving reasons.

\subsubsection{Creating New Stock Records with \texttt{insert-stock}}

\begin{lstlisting}
  Usage: insert-stock.js [-f <json file>]
\end{lstlisting}

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/insert-stock.png}
  \caption{Inserting a stock record from a JSON file with
    \texttt{insert-stock}.}
  \label{fig:insert-stock}
\end{figure}

The \texttt{insert-stock} utility provides an interface for quickly inserting
new stock and security records into the database from the command line. The tool
allows the user to manually enter stock data line-by-line, terminating input
with the End-of-Document (Ctrl-d) character, or accepts input piped from another
command in the usual *nix way. Additionally, with the \texttt{-f} flag, the tool
will read input from a file on disk. Whether input is passed from a file, pipe,
or direct input, \texttt{insert-stock} expects to read data in standard JSON
format. Like MongoDB, it will process \texttt{\$oid} and \texttt{\$date} fields
into native Mongo/Javascript \texttt{ObjectID} and \texttt{Date} objects. Other
fields may not parse correctly; however, it should be trivial to add rules for
additional field types in the \texttt{convertMongoQueryFields} function in
\texttt{jsonUtils.js}, discussed later.

Internally, the utility wraps around \texttt{db.dataCreate}, which provides
a simplified interface to the MongoDB driver \texttt{insertOne} and
\texttt{insertMany} methods, automatically selecting the appropriate method
for the document object passed as an argument.

\begin{figure}[bp]
  \includegraphics[width=\textwidth]{build/img/insert-stock-v.png}
  \caption{Verifying that the stock QX inserted correctly.}
  \label{fig:insert-stock-v}
\end{figure}

Figure \ref{fig:insert-stock} illustrates the utility being used to insert a new
stock record\footnote{Which is definitely not just a copy of the record for
China Zenix Auto International (ZX) with the first letter of its ticker symbol
and first character of its ObjectID changed...} being inserted into the
database, while Figure \ref{fig:insert-stock-v} confirms that the record has
been inserted successfully.

\subsubsection{Updating Trade Volumes with \texttt{update-volume}}

\begin{lstlisting}
  Usage: update-volume [-t <ticker>] [-v <volume>]
\end{lstlisting}

Where \texttt{insert-stock} has a broad purview, \texttt{update-volume} is a
tightly-focused single-purpose tool. It wraps the \texttt{db.dataUpdate}
function in a simple interface, prompting the user for a ticker symbol and
updated value and updating the database accordingly. Because
\texttt{db.dataUpdate} expects its input as a key-value object, the wrapper
includes a bit of logic to transform the input---which can optionally be passed
at command invocation with UNIX-style flags---into appropriate query and update
documents.

Figure \ref{fig:update-volume} depicts both the tool in operation and its
verification by piping output from \texttt{stock-client read} through
\texttt{grep} to focus on only the lines containing the stock's ticker symbol
and volume data.

\begin{figure}[tbp]
  \includegraphics[width=\textwidth]{build/img/update-volume.png}
  \caption{Using \texttt{update-volume} to update the \texttt{Volume} field on
    our dummy stock, `QX'.}
  \label{fig:update-volume}
\end{figure}

\subsubsection{Deleting Existing Stock Records with \texttt{delete-ticker}}

\begin{lstlisting}
  Usage: delete-ticker [-t <ticker>]
\end{lstlisting}

At this point, astute readers might be wondering, ``but now that I've added this
worthless dummy stock record and changed one value, how do I remove it from the
database so it doesn't pollute my analysts' reports?'' Fortunately, the
\texttt{delete-ticker} utility gives administrators a simple, effective tool to
do just that. The utility wraps around the \texttt{db.dataDelete} function,
which it supplies with a query on the ticker symbol provided by the user. Like
\texttt{update-volume}, \texttt{delete-ticker} can take input in the form of a
command line flag, or it will prompt the user to enter a ticker symbol if one is
not provided. Figure \ref{fig:delete-ticker} illustrates the use of
\texttt{delete-ticker} without providing a ticker at the command line.

\begin{figure}[tbp]
  \includegraphics[width=\textwidth]{build/img/delete-ticker.png}
  \caption{Deleting the `QX' stock record with \texttt{delete-ticker}. Again,
    read output is piped for brevity. Note that this usage omits the command
    line flag, opting to use the prompt for ticker entry, instead.}
  \label{fig:delete-ticker}
\end{figure}

\subsubsection{\texttt{sma-spread}, a Demonstration of Find Queries}

\begin{lstlisting}
  Usage: sma-spread.js [-l <low value>] [-h <high value>]
\end{lstlisting}

Read operations are the bread and butter of an analytical database system such
as STOCKS. While administrators might spend more time with document insertion
and manipulation, the bulk of the system's user base will inevitably be
analysts, tasked with querying the compiled data and drawing conclusions about
the appropriate direction to take the company and its clients in the days and
weeks to come. In developing STOCKS, it became clear early on that no set of
queries developed by the back-end team could---or even should---fulfill all
foreseeable needs encountered by the analysis team; instead, we provide
examples, in the hopes of empowering the analysts to find their need and fill it.

\begin{figure}[bp]
  \includegraphics[width=\textwidth]{build/img/sma-spread.png}
  \caption{The \texttt{sma-spread} tool in action.}
  \label{fig:sma-spread}
\end{figure}

While most analysts will choose to leverage the tools made available by the
front-end team or work directly with the STOCKS Web Service API to construct
these queries and gather this data, there remains a need for command line tools
for analysis. To this end, \texttt{sma-spread} should be viewed not so much as a
tool in itself, but rather as a blueprint of what a command line tool built on
Node and the STOCKS libraries might look like. The \texttt{sma-spread} follows
the pattern established in the tools presented earlier. It wraps a thin layer of
logic around the \texttt{db.countMatching} function to transform user input into
a query object that can be passed to the data access layer directly. In this
case, that query object is a simple range query, using MongoDB's \texttt{\$gt}
and \texttt{\$lt} conditionals to search for Simple Moving Average values within
user-specified bounds. For brevity, this function only returns a count of
matching values; however, it would be trivial to amend this to return a list of
values using \texttt{db.dataRead}\footnote{At which point, the author hopes,
they would be processed, and not just dumped to \texttt{stdout}.}.

\subsubsection{Generating a List of Ticker Symbols for a Given Industry}

\begin{lstlisting}
  Usage: tickers-by-industry [-i <industry>]
\end{lstlisting}

As with any tool built on a powerful, feature-rich back end like MongoDB, it
would be impossible to expose all of the low-level functionality of the Node
MongoDB driver in the STOCKS command line tools or Web Service API. Writing
tools in such a framework would hardly be better than developing with the
MongoDB driver API directly. However, in abstracting away the complexities of
connecting to and manipulating the MongoDB database, some functionality
inevitably falls by the wayside.

\begin{figure}[bp]
  \includegraphics[width=\textwidth]{build/img/tickers-by-industry.png}
  \caption{The \texttt{tickers-by-industry} utility in action.}
  \label{fig:tickers-by-industry}
\end{figure}

The \texttt{tickers-by-industry} utility is a perfect example of this sort of
compromise. In the interest of simplifying the method signature for
\texttt{db.dataRead}, we chose to omit the option to limit what fields the query
returns. As a result, logic to limit the returned results from
\texttt{tickers-by-industry} relies on a simple JavaScript loop to print only
the stock ticker symbols to the console. This sort of client-side workaround
isn't ideal, as there is a performance cost incurred as the script iterates over
the returned array, but that cost is often negligible. Figure
\ref{fig:tickers-by-industry} illustrates the \texttt{tickers-by-industry}
utility retrieving a ticker list for the industry matching the most results,
showing a total execution time of just under a second on the author's decade-old
workstation. While there are certainly cases where client-side
processing would place undue burden on the client, or where server-side
processing can leverage significantly more performant technologies, the cost
often does not justify the added complexity in back-end code.

\subsubsection{Generating a List of Outstanding Shares by Industry}

\begin{lstlisting}
  Usage: agg-shares.js [-s <sector>]
\end{lstlisting}

The \texttt{agg-shares} utility follows a similar pattern to the other
string-fed\footnote{Not to be confused with grain-fed. We raise our command line
utilities using traditional techniques, feeding them a healthy diet of caffeine
and suffering like civilized programmers.} tools presented above. It takes input
from a user prompt or, optionally, a command line argument. In this case,
\texttt{agg-shares} asks for a sector, and returns a sorted list of industries
in that sector, along with the total number of shares outstanding in the
industry. This utility illustrates, to a small extent, what can be done with
MongoDB's aggregation framework, one of its most powerful features. Because the
STOCKS application's data access layer function \texttt{db.dataAggregate}
accepts MongoDB aggregation pipeline arrays directly, any operation that can be
conducted as part of an aggregation pipeline can be executed through the STOCKS
aggregation functionality.

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/agg-shares.png}
  \caption{\texttt{agg-shares} operating on the ``Utilities'' industry (chosen
    for brevity).}
  \label{fig:agg-shares}
\end{figure}

While a full discussion of MongoDB's aggregation framework is well outside the
scope of this document, a brief overview of the functions utilized in
\texttt{agg-shares} is both reasonable and warranted. Three aggregation stages
are used in this pipeline: (a) a \texttt{\$match} stage matching records
with the \texttt{Sector} field value specified; (b) a \texttt{\$group} stage,
which collects records into groups by industry and sums their outstanding
shares; and (c) a \texttt{\$sort} stage, which is responsible for ordering the
results in descending order by total shares outstanding. This pipeline is passed
directly to the \texttt{db.dataAggregate} function, which returns the results.
Additional processing occurs on the client side; the utility uses a JavaScript
implementation of C's \texttt{printf} function to format each result before
printing it to screen in nice, neat, orderly columns\footnote{It's worth noting
  that \texttt{agg-shares} breaks when included in a UNIX pipe. I'm not really
  sure why this is---it throws a Node error and complains about writing to a
  pipe, but I'm not entirely sure what's going wrong.}. Figure
\ref{fig:agg-shares} illustrates the tool in operation on the ``Utilities''
sector.

\section{The STOCKS Web Service API}

While the command line utilities in the first section offer insight into how
STOCKS works under the hood, the meat of the application is dedicated to
providing the STOCKS Web Service API. The Web Service API is built on a layered
architecture model centered on a separation of concerns. The core of this
architecture is the Data Access layer, described in part in the first section,
which wraps around the MongoDB driver methods. Above the Data Access layer, a
Services layer contains business logic that processes input data before passing
it to Data Access functions and output data to be returned to the route's
Controller. This Controller contains logic associated with the particular web
service framework---in this case, the venerable Express framework. At the most
abstract, the Routing layer takes incoming requests and passes them to the
appropriate controller for processing.

This architecture is ideal both for a rapidly-growing startup and the fluid
ecosystem of Node.js. By writing business logic in simple, standard JavaScript,
developers can focus on the logic itself, rather than the vagaries of Express.
Conversely, when the tides shift and Express inevitably falls out of favor,
developers need only focus on transitioning the routing and request handling
logic to whatever new, shiny tech is in vogue. This approach does add some
complexity---not counting the command line utilities, the resulting codebase is
spread across a dozen files---but the scalability and sustainability of this
approach are worth the cost.

Contrary to the breakdown above, this section breaks the API down into its six
endpoints, four for the basic CRUD operations fundamental to any database
system, along with two examples of more complex read operations. These endpoints
are far from comprehensive; like the command line tools, the API presented aims
to provide a minimal level of pre-built functionality which can serve as a
framework and inspiration for more complex workflows.

\subsection{A Brief Return to \texttt{stock-client.sh}}

Because the \texttt{stock-client} script is arguably the most distilled form of
a client designed to access the STOCKS Web Service API---and because it is
written in Bash, not JavaScript---it seems appropriate to revisit it in this
section as an example of the versatility of the API. While the client is by no
means a complete illustration of what could be done with a dedicated front-end
solution, it effectively demonstrates the power of the REST model. As API
requests are passed in JSON, rather than as proprietary binary data or native
language constructs, the client accessing the REST resources is not constrained
to any one language, architecture, or methodology. While it is a simple tool,
the \texttt{stock-client} script is eminently usable: it offers a concise
command syntax; offers readable, paged output; and allows the user to manipulate
data once it has been retrieved. That usability and power is, of course,
predicated on a familiarity with UNIX tools and concepts. However, a software
application \textit{should} tailor itself to its target user. A client for
non-technical users could just as easily offer all of the graphical bells and
whistles that those users expect while still harnessing the same API.

\subsection{Basic CRUD Operations}

At the core of the STOCKS Web Service API are the four CRUD operations. These
four functions form the building blocks that front-end developers can use to
build their interfaces. While they do not expose all of the features of the
underlying layers, their simplicity makes them powerful in their own right.

\subsubsection{\texttt{createStock}}

\begin{lstlisting}
  URI:    http://<hostname>:<port>/api/v1.0/createStock/<ticker>
  Method: POST
\end{lstlisting}

Before data can be analyzed or modified, it must first be created. The create
endpoint empowers users to create these stock records, and is intended to be
used primarily in an administrative capacity. A \texttt{createStock} request
takes the form of a POST request directed at the \texttt{createStock/<ticker>}
URI. This variable URI field, called a \textit{parameter}, indicates to the
system the stock ticker symbol of the record to be created, while the body of
the request is a JSON stock record document. Provision of the ticker symbol in
the URI provides a modicum of validation; if the ticker in the request body does
not match the URI parameter, the request is rejected.

Once this validation is performed, the controller calls
\texttt{services.stocks.createStockService}, which converts any MongoDB query
fields, such as \texttt{\$oid} or \texttt{\$date}, into native JavaScript
objects of the appropriate type. It then validates that the stock record does
not already exist in the database. Assuming the record is unique, the service
calls the data access function \texttt{db.dataCreate} to insert the stock record
document into the database. The ultimate success of the insert---or its failure
at any stage---is returned to the controller, which responds to the original
request with code 201 for a successful insert, 400 if the ticker already exists
in the database, or 500 if the server encounters another error.

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/createStock.png}
  \caption{Successful insertion of `QX', a bald-faced copy of the stock record
    for China Zenix Auto International Ltd., with filtered \texttt{readStock}
    output for verification.}
  \label{fig:createStock}
\end{figure}

The \texttt{stock-client} front end simplifies usage of the
\texttt{createStock} endpoint by assembling an appropriate \texttt{curl} command
from the JSON data passed by the user. Figure
\ref{fig:createStock} shows the utility making a \texttt{createStock} request
with the command:

\begin{lstlisting}[language=bash]
  curl -H "Content-Type: application/json" \
        -X POST -d "$inputjson" -s \
        "http://$hostname:3000/api/v1.0/createStock/$ticker"
\end{lstlisting}

\subsubsection{\texttt{readStock}}

\begin{lstlisting}
  URI:    http://<hostname>:<port>/api/v1.0/readStock/<ticker>
  Method: GET
\end{lstlisting}

The \texttt{readStock} API endpoint provides a significant amount of
functionality to the end user and front-end developer. Because it returns highly
detailed data about a single stock record, it can be used in a targeted query
against a single record, or to collect information about several different
records using client-side language features, akin to the strategy used by the
\texttt{tickers-by-industry} command line tool demonstrated in the first
section. While more complex queries or searches looking for detailed data on
long lists of individual stocks might be better served with a single-request API
endpoint utilizing aggregation or complex \texttt{find} functionality, the
increase in query performance may not justify the increased development effort
in many cases. That being said, the sections on the advanced query endpoints
\texttt{tickerList} and \texttt{industryReport} illustrate the ease with which
new API endpoints can be added, if necessary.

Requests to \texttt{readStock} take the form of an HTTP GET request; the query
variable, \texttt{Ticker}, is passed through a URI parameter in the final
position. This request is routed to \texttt{stocks.readStockController},
which extracts the parameter object---which shares the same structure as the
desired MongoDB query document---and passes it to the basic read service.
This service calls the data access layer directly, and returns the resulting
array to the controller. If the array is empty, the controller sends an HTTP 404
response, indicating that the item does not appear in the records\footnote{And,
  therefore, does not exist.}. Otherwise, the controller responds with the data
as a JSON string.

The \texttt{readStock} API endpoint has been demonstrated throughout this
document, as the \texttt{stock-client} script implements calls to the API in its
\texttt{read} interface. The \texttt{curl} command used by the client is:

\begin{lstlisting}
  curl "http://$hostname:3000/api/v1.0/readStock/$ticker" -s
\end{lstlisting}

\subsubsection{updateStock}

\begin{lstlisting}
  URI: http://<hostname>:<port>/api/v1.0/updateStock/<ticker>
  Method: PUT
\end{lstlisting}

Updating stock records with the Web Service API works similarly to other basic
CRUD operations. The URI follows the same structure, with calls to
\texttt{updateStock} followed by a single positional parameter indicating the
target stock ticker. Like requests to \texttt{createStock},
\texttt{updateStock} takes additional JSON data in the request body; however,
unlike \texttt{createStock} requests, this data need not contain a matching
ticker symbol. In fact, the JSON request body should contain only the fields
the user wants to update, with their new values. Processing of this document
into a MongoDB \texttt{\$set} query is handled by the STOCKS application.

After the incoming request is routed to the \texttt{stocks.readController}, the
controller verifies that the record exists, then extracts URI parameter object
and the request body. These objects are passed to the update service as the
\texttt{query} and \texttt{update} parameters, respectively. The query object is
already in the correct form to send to the data access layer, but the service
sets the \texttt{update} parameter as the value in a MongoDB \texttt{\$set}
key-value pair before it is passed to \texttt{db.dataUpdate}. Assuming the
update completes successfully, the service returns the result to the controller.
If the \texttt{result} object indicates that no records were updated---such as
would be the case if the fields to be updated already contained the values
requested---the server responds with a message indicating that the record was
not modified; otherwise, the message indicates that the update was successful.
In both cases, the response code sent to the client is 200, indicating that the
value(s) of the specified fields match those requested.

The \texttt{updateStock} endpoint is accessed by \texttt{stock-client} using the
\texttt{curl} command below, and is illustrated in operation in Figure
\ref{fig:updateStock}.

\begin{lstlisting}
  curl -H "Content-Type: application/json" \
       -X PUT -d "$inputjson" -s \
       "http://$hostname:3000/api/v1.0/updateStock/$ticker"
\end{lstlisting}

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/updateStock.png}
  \caption{\texttt{stock-client} demonstrating successful execution of a call to
    the \texttt{updateStock} endpoint (and YAML document input, but that's not
    the point).}
  \label{fig:updateStock}
\end{figure}

\subsubsection{\texttt{deleteStock}}

\begin{lstlisting}
  URI:    http://<hostname>:<port>/api/v1.0/deleteStock/<ticker>
  Method: DELETE
\end{lstlisting}

\begin{figure}[bp]
  \includegraphics[width=\textwidth]{build/img/deleteStock.png}
  \caption{A call to the \texttt{deleteStock} endpoint successfully deleting a stock
    record from the database.}
  \label{fig:deleteStock}
\end{figure}

Like the other CRUD operations, the API endpoint is accessed through an HTTP
request with a \texttt{Ticker} parameter in the final position. In this case,
the request is made as a DELETE request, which takes no additional data. This
request is routed to \texttt{stocks.deleteStockController}, which extracts the
parameter object and passes it to the delete service. This service is a thin
wrapper around the \texttt{db.dataDelete} function. Once the data access layer
returns a MongoDB result object, this result is passed to the controller; on a
successful deletion, the server responds to the client with an HTTP 200 response
indicating the record was successfully deleted. If the record was not found, it
returns code 404.

The \texttt{curl} command for this request is essentially identical to that
passed to \texttt{readStock}, with the addition of a \texttt{-X DELETE} flag
indicating the request type. Its execution is illustrated in Figure
\ref{fig:deleteStock}.

\subsection{Advanced Reporting}

MongoDB is an incredibly powerful database system, and it offers features which
can greatly simplify and enhance complex reporting use cases. It would be
impossible to cover all possible reports that a particular customer might desire
for even an application as simple as STOCKS; however, the decision to build the
STOCKS back end on the Node.js platform makes it straightforward for front-end
developers with JavaScript skills to enhance the back end with additional
reports, as necessary. The two reports included in this section are designed to
provide examples of the possibilities the system offers and inspiration for
future front- and back-end developers alike.

\subsubsection{\texttt{stockReport}}

\begin{lstlisting}
  http://<hostname>:<port>/api/v1.0/stockReport
\end{lstlisting}

The \texttt{stockReport} API endpoint presents a common use case for more
advanced reporting functionality; rather than seeking detailed information on a
single stock, a user is likely to want to compare data about several stocks.
This API facilitates these queries by allowing the user to enter a list of
ticker symbols\footnote{Technically, a JSON array.}, which is transformed into
query that leverages MongoDB's \texttt{\$in} operator.

\texttt{stockReport} is the only API endpoint in the application that doesn't
take a positional parameter; instead, it takes input, in the form of a JSON
array, as the body of an HTTP POST request to the base URI. This array,
extracted from the request body by the controller, is passed to the service
layer, where it is inserted into a MongoDB \texttt{\$in} query object, which is
passed to \texttt{db.dataRead}. The array of results is returned to the
controller, which sends it in the body of an HTTP 200 response to the client.
This approach leaves further filtering of displayed fields to the client,
focusing instead on streamlining data retrieval for multiple stock tickers.

The sample client included with the STOCKS application provides an example of
this client-side data processing, passing the returned data through \texttt{jq}
to limit the number of fields displayed on the terminal. However, a client could
execute commands of arbitrary complexity on the returned data, depending on its
needs. Figure \ref{fig:stockReport} shows an example of the \texttt{stockReport}
API endpoint and this client-side processing.

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/stockReport}
  \caption{\texttt{stock-client} running a stock report request to the
    \texttt{stockReport} API endpoint. Note that data processing is happening on
    the client side with \texttt{jq}.}
  \label{fig:stockReport}
\end{figure}

\subsubsection{\texttt{industryReport}}

\begin{lstlisting}
  http://<hostname>:3000/api/v1.0/industryReport/<industry>
\end{lstlisting}

The \texttt{industryReport} endpoint offers an example of injecting user input
into a pre-constructed aggregation pipeline designed to generate a specific type
of report. It takes a single positional parameter, an \texttt{Industry} string,
and returns a list of the top five stock choices in that industry. The actual
logic to do this is surprisingly simple, making this an excellent example of the
ways that a team could extend the application to suit their needs.

After receiving the routed request, the controller extracts the industry string
from the URI parameter and passes it to the service layer. The service layer
receives this string and inserts it into a three-stage MongoDB aggregation
pipeline array. This pipeline consists of a \texttt{\$match} stage targeting
the user-supplied industry string, a \texttt{\$sort} stage that sorts by analyst
recommendation rating, and a \texttt{\$limit} stage that returns only the top
five results. This pipeline is passed to \texttt{db.dataAggregate}, which
performs the database operation and returns the resulting array to the service
layer, which sends it to the controller. Assuming the operation executes
successfully, the controller sends the array to the client as a JSON string.

\begin{figure}[tp]
  \includegraphics[width=\textwidth]{build/img/industryReport.png}
  \caption{An \texttt{industryReport} run by \texttt{stock-client}}
  \label{fig:industryReport}
\end{figure}

This example is an excellent demonstration of the extensibility of the STOCKS
platform---not only because it shows \textit{how} the system can be extended to
cover additional use cases by the front-end team or eventual end users, but
because it shows \textit{why} those users may want to develop such functionality
themselves. The field of financial services is broad, complex, and technical,
and this developer has essentially no knowledge of what makes a stock a ``top
stock''. Relying on a single number, even a ``recommendation,'' is a poor
substitute for the detailed understanding that professionals in the field
possess; it is far more practical, in this case and many like it, to provide
tools that those who have this knowledge can employ to gain the insights they
seek than it is to try to foresee every need without that background.

Figure \ref{fig:industryReport} illustrates a call to the
\texttt{industryReport} API using \texttt{stock-client}. As with
\texttt{stockReport}, additional data processing occurs on the client side,
using \texttt{jq}.

\end{document}
